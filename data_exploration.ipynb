{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "35000  Just don't bother. I thought I would see a mov...  negative\n",
      "35001  Be careful with this one. Once you get yer mit...  positive\n",
      "35002  Chili Palmer is tired of doing movies and know...  negative\n",
      "35003  Following is a little-known 1998 British film,...  positive\n",
      "35004  Dark Angel is a cross between Huxley's Brave N...  positive\n",
      "...                                                  ...       ...\n",
      "44995  I watched this movie for the first time a few ...  negative\n",
      "44996  I am a sucker for films like this. Films that ...  positive\n",
      "44997  I am a college student studying a-levels and n...  positive\n",
      "44998  huge Ramones fan. i do like the ramones, and i...  positive\n",
      "44999  I rented this movie yesterday and can hardly e...  negative\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/IMDB Dataset.csv')\n",
    "train_slice = int(len(data)*0.7)\n",
    "val_slice = train_slice + int(len(data)*0.2)\n",
    "#test_slice = val_slice + int(len(data)*0.1)\n",
    "train_data = data[:train_slice]\n",
    "val_data = data[train_slice:val_slice]\n",
    "test_data = data[val_slice:]\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232k/232k [00:00<00:00, 1.42MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "VOCAB_FILE = \"https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\"\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 512\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "            T.BERTTokenizer(vocab_path=VOCAB_FILE),\n",
    "            T.StrToIntTransform(),\n",
    "            #T.VocabTransform(),\n",
    "            T.Truncate(max_seq_len - 2),\n",
    "            #T.AddToken(token=bos_idx, begin=True),\n",
    "            #T.AddToken(token=eos_idx, begin=False),\n",
    "            T.ToTensor(),\n",
    "            T.PadTransform(max_seq_len, pad_value = 0)\n",
    "        )\n",
    "\n",
    "all_lines = [line for line in data['review']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2028,  1997,  1996,  2060, 15814,  2038,  3855,  2008,  2044,  3666,\n",
       "         2074,  1015, 11472,  2792,  2017,  1005,  2222,  2022, 13322,  1012,\n",
       "         2027,  2024,  2157,  1010,  2004,  2023,  2003,  3599,  2054,  3047,\n",
       "         2007,  2033,  1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,\n",
       "         1028,  1996,  2034,  2518,  2008,  4930,  2033,  2055, 11472,  2001,\n",
       "         2049, 24083,  1998,  4895, 10258,  2378,  8450,  5019,  1997,  4808,\n",
       "         1010,  2029,  2275,  1999,  2157,  2013,  1996,  2773,  2175,  1012,\n",
       "         3404,  2033,  1010,  2023,  2003,  2025,  1037,  2265,  2005,  1996,\n",
       "         8143, 18627,  2030,  5199,  3593,  1012,  2023,  2265,  8005,  2053,\n",
       "        17957,  2007, 12362,  2000,  5850,  1010,  3348,  2030,  4808,  1012,\n",
       "         2049,  2003, 13076,  1010,  1999,  1996,  4438,  2224,  1997,  1996,\n",
       "         2773,  1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,\n",
       "         2009,  2003,  2170, 11472,  2004,  2008,  2003,  1996,  8367,  2445,\n",
       "         2000,  1996, 17411,  4555,  3036,  2110,  7279,  4221, 12380,  2854,\n",
       "         1012,  2009,  7679,  3701,  2006, 14110,  2103,  1010,  2019,  6388,\n",
       "         2930,  1997,  1996,  3827,  2073,  2035,  1996,  4442,  2031,  3221,\n",
       "        21430,  1998,  2227, 20546,  2015,  1010,  2061,  9394,  2003,  2025,\n",
       "         2152,  2006,  1996, 11376,  1012,  7861,  2103,  2003,  2188,  2000,\n",
       "         2116,  1012,  1012, 26030,  2015,  1010,  7486,  1010, 18542, 10230,\n",
       "         1010,  7402,  2015,  1010,  8135,  1010, 16773,  1010,  3493,  1998,\n",
       "         2062,  1012,  1012,  1012,  1012,  2061,  8040, 16093, 28331,  1010,\n",
       "         2331, 14020,  1010, 26489,  6292, 24069,  1998, 22824, 10540,  2024,\n",
       "         2196,  2521,  2185,  1012,  1026,  7987,  1013,  1028,  1026,  7987,\n",
       "         1013,  1028,  1045,  2052,  2360,  1996,  2364,  5574,  1997,  1996,\n",
       "         2265,  2003,  2349,  2000,  1996,  2755,  2008,  2009,  3632,  2073,\n",
       "         2060,  3065,  2876,  1005,  1056,  8108,  1012,  5293,  3492,  4620,\n",
       "         4993,  2005,  7731,  9501,  1010,  5293, 11084,  1010,  5293,  7472,\n",
       "         1012,  1012,  1012, 11472,  2987,  1005,  1056,  6752,  2105,  1012,\n",
       "         1996,  2034,  2792,  1045,  2412,  2387,  4930,  2033,  2004,  2061,\n",
       "        11808,  2009,  2001, 16524,  1010,  1045,  2481,  1005,  1056,  2360,\n",
       "         1045,  2001,  3201,  2005,  2009,  1010,  2021,  2004,  1045,  3427,\n",
       "         2062,  1010,  1045,  2764,  1037,  5510,  2005, 11472,  1010,  1998,\n",
       "         2288, 17730,  2000,  1996,  2152,  3798,  1997,  8425,  4808,  1012,\n",
       "         2025,  2074,  4808,  1010,  2021, 21321,  1006, 15274,  4932,  2040,\n",
       "         1005,  2222,  2022,  2853,  2041,  2005,  1037, 15519,  1010, 13187,\n",
       "         2040,  1005,  2222,  3102,  2006,  2344,  1998,  2131,  2185,  2007,\n",
       "         2009,  1010,  2092,  5450,  2098,  1010,  2690,  2465, 13187,  2108,\n",
       "         2357,  2046,  3827,  7743,  2229,  2349,  2000,  2037,  3768,  1997,\n",
       "         2395,  4813,  2030,  3827,  3325,  1007,  3666, 11472,  1010,  2017,\n",
       "         2089,  2468,  6625,  2007,  2054,  2003,  8796, 10523,  1012,  1012,\n",
       "         1012,  1012,  2008,  2015,  2065,  2017,  2064,  2131,  1999,  3543,\n",
       "         2007,  2115,  9904,  2217,  1012,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_transform(all_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.Tensor([1.0]) == torch.Tensor([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truncate()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3616\n",
      "331.11734\n"
     ]
    }
   ],
   "source": [
    "tokenized_data_len = [len(test_text_transform(line)) for line in data['review']]\n",
    "\n",
    "print(max(tokenized_data_len))\n",
    "print(sum(tokenized_data_len)/len(tokenized_data_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/xeon/text_classification/notebooks/data_exploration.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xeon/text_classification/notebooks/data_exploration.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xeon/text_classification/notebooks/data_exploration.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(tokenized_data_len)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xeon/text_classification/notebooks/data_exploration.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/binary_sherlock/lib/python3.11/site-packages/matplotlib/_api/__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m props:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m props[name]\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance)\n\u001b[0;32m--> 217\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "plt.plot(tokenized_data_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.reset_index()\n",
    "\n",
    "val_data['review'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binary_sherlock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
